from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from routers import classifier, embedder

limiter = Limiter(key_func=get_remote_address)

app = FastAPI(
    title="ML Inference API",
    description="Zero-shot classification and sentence embedding endpoints",
    version="1.0.0"
)

app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(classifier.router, prefix="/api", tags=["classifier"])
app.include_router(embedder.router, prefix="/api", tags=["embedder"])

@app.get("/")
@limiter.limit("100/minute")
async def root(request: Request):
    return {
        "message": "ML Inference API is running",
        "docs": "/docs",
    }
    
@app.get("/health")
@limiter.limit("200/minute")
async def health_check(request: Request):
    return {"status": "healthy"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
    